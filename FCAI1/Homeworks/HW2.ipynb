{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Instructions:**\n",
        "\n",
        "Tasks in this homework are based on what is covered in laboratory exercises 3 and 4.\n",
        "\n",
        "When you finish, download and upload the notebook file in .ipynb format to c3 homework 2 assignment section."
      ],
      "metadata": {
        "id": "wzzY0aZuQ0eB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "02KuF5bOsw6s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c505777-7135-4ad5-9581-75f27023b09f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Course: Fundamental Concepts of AI**\n",
        "\n",
        "#**Homework 2: Working with datasets**\n",
        "\n"
      ],
      "metadata": {
        "id": "MQtLIqo7RhZT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Student name and surname:*\n",
        "Almir Mustafic\n",
        "**Student index:**\n",
        "20114\n",
        "**Date:**\n",
        "December 2, 2024"
      ],
      "metadata": {
        "id": "MhYVVX6IR-G_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Comment on Homework 2*\n",
        "As I was not sure wether or not we need to include the exercises from the Assignment (PDF), I am providing a [LINK](https://colab.research.google.com/drive/1wWv1Qpo3e3-maNM3F1Ru9fhsFiddlT7F) to the colab where I complete the class exercises:"
      ],
      "metadata": {
        "id": "pLIFLT2_clGE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Assignment 1: Stellar Classification Dataset - SDSS17** (2 points)\n",
        "\n",
        "**Classification of Stars, Galaxies, and Quasars**  \n",
        "The dataset for this task comes from the Sloan Digital Sky Survey (SDSS). It contains observations of celestial objects and their spectral characteristics. You can find the dataset and its description at this [Kaggle link](https://www.kaggle.com/datasets/fedesoriano/stellar-classification-dataset-sdss17/data). Download the dataset from the link and load it like you did in the labs.\n",
        "\n",
        "### **Instructions**  \n",
        "Perform the following tasks:\n",
        "\n",
        "---\n",
        "\n",
        "### **1. Dataset Overview**  \n",
        "1. What is the dataset about?  \n",
        "2. What is the format/type of this dataset?  \n",
        "3. For which task is this dataset used (e.g., classification, regression, etc.)?  \n",
        "4. What are the inputs and what are the outputs?  \n",
        "5. How many samples/instances are in this dataset?  \n",
        "6. List all features and explain their meanings.  \n",
        "7. List all targets/labels in the dataset.  \n",
        "8. Draw a black-box input-output diagram for the dataset.  \n",
        "9. What are the data types for each column in the dataset?  \n",
        "\n",
        "---\n",
        "\n",
        "### **2. Data Exploration**  \n",
        "1. Display the first 5 and last 5 rows of the dataset.  \n",
        "2. Check if there are any missing values in the dataset for each column.  \n",
        "3. What is the class distribution in the dataset? Use the `data['class'].value_counts()` function to calculate the number of samples for each class.  \n",
        "\n",
        "---\n",
        "\n",
        "### **3. Statistical Analysis**  \n",
        "1. Use the `data.describe()` method to display the minimum, maximum, mean, standard deviation, and percentiles (20%, 50%, and 75%) for numerical features.  \n",
        "2. Plot a bar plot for the class distribution. Ensure your plot has:  \n",
        "   - Axis labels  \n",
        "   - A descriptive title  \n",
        "   - Color and name for each class bar\n",
        "3. Choose two features (e.g., `delta` and `alpha`) and create a 2D scatter plot to visualize patterns in the dataset. Color the points according to their class. Make sure to add:  \n",
        "   - Axis labels  \n",
        "   - A descriptive title  \n",
        "   - A legend  \n",
        "\n",
        "---\n",
        "\n",
        "### **4. Data Cleaning and Preparation**  \n",
        "1. Discard all columns that represent IDs or metadata (e.g., `obj_ID`, `run_ID`, `plate`, etc.) because those are not particullary useful for ML models. Retain only the following columns:  \n",
        "   - `u`, `g`, `r`, `i`, `z`, `redshift`, and `class`.  \n",
        "2. Print the cleaned dataset.  \n",
        "\n",
        "---\n",
        "\n",
        "### **5. Data Saving**\n",
        "\n",
        "1. Save the cleaned dataset to a file named stellar_cleaned.csv, using a semicolon (;) as the separator.\n",
        "2. Verify that the saved file can be reloaded correctly and print the first few rows to confirm.\n",
        "\n",
        "Submit your answers with detailed explanations, well-documented code, and all required plots included."
      ],
      "metadata": {
        "id": "G62SbJkqbpGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# install kaggle and set the API key (token)\n",
        "# os.environ['KAGGLE_CONFIG_DIR'] = '/content/drive/MyDrive/Colab Notebooks/'\n",
        "# !kaggle datasets list\n",
        "# ! pip install -q kaggle\n",
        "# files.upload()\n",
        "# ! mkdir ~/.kaggle\n",
        "# ! cp kaggle.json ~/.kaggle/\n",
        "# ! chmod 600 ~/.kaggle/kaggle.json\n",
        "# ! kaggle datasets list\n",
        "\n",
        "# Load the dataset\n",
        "stars = '/content/drive/MyDrive/Colab Notebooks/star_classification.csv'\n",
        "data = pd.read_csv(stars)\n",
        "\n",
        "# 1.1) What is the dataset about?\n",
        "# The dataset contains data on astronomical objects from the Sloan Digital Sky Survey (SDSS). The dataset includes different\n",
        "# attributes (e.g., photometric magnitudes in different bands, redshift, etc.) for astronomical objects classified into three\n",
        "# categories galaxies, stars and quasars.\n",
        "\n",
        "# 1.2) What is the format/type of this dataset?\n",
        "# The dataset is in CSV file and of tabular format, where each row represents an astronomical object, and each column contains a specific\n",
        "# attribute of the object.\n",
        "\n",
        "# 1.3) For which task is this dataset used (e.g., classification, regression, etc.)?\n",
        "# The dataset is primarily used for classification tasks with the goal to classify the astronomical objects into one of the classes\n",
        " # (galaxy, star, qso). The classification is based on various input features.\n",
        "\n",
        "# 1.4) What are the inputs and what are the outputs?\n",
        "# The inputs are the columns that describe the characteristics of the astronomical objects: u, g, r, i, z: Magnitudes in different photometric bands.\n",
        "# The redshift of the object is a measure of how much the object's light has been stretched due to the expansion of the universe.\n",
        "# The output is the class column that indicates the class of the astronomical object.\n",
        "\n",
        "# 1.5) How many samples/instances are in this dataset?\n",
        "# 100000    code to check: data.shape[0]\n",
        "\n",
        "# 1.6) List all features and explain their meanings.\n",
        "# u, g, r, i, z are magnitudes in different photometric bands measured by the SDSS telescope. They correspond to different wavelengths\n",
        "# in the electromagnetic spectrum, that is ultraviolet to infrared.\n",
        "# The redshift is a measure of how much the wavelength of light from an astronomical object has been stretched due to the expansion of the universe.\n",
        "# This measure helps estimate the distance of a specific object from Earth.\n",
        "# Class represents the type or classification of the astronomical object.\n",
        "\n",
        "# 1.7) List all targets/labels in the dataset.\n",
        "# Galaxy, QSO and star.\n",
        "\n",
        "# 1.8) Draw a black-box input-output diagram for the dataset.\n",
        "#    +------------------------------------+\n",
        "#    |                                    |\n",
        "#    |           Input Features           |\n",
        "#    |                                    |\n",
        "#    |  u, g, r, i, z, redshift          |\n",
        "#    |                                    |\n",
        "#    +------------------------------------+\n",
        "#               |     (Classification)\n",
        "#               v\n",
        "#    +------------------------------------+\n",
        "#    |                                    |\n",
        "#    |         Output (Class Label)       |\n",
        "#    |                                    |\n",
        "#    |          GALAXY, QSO, STAR         |\n",
        "#    |                                    |\n",
        "#    +------------------------------------+\n",
        "\n",
        "# 1.9) What are the data types for each column in the dataset?\n",
        "# Code to check:\n",
        "# data.dtypes\n",
        "# obj_ID:\tfloat64, alpha:\tfloat64, delta:\tfloat64, u: float64, g:\tfloat64, r:\tfloat64, i:\tfloat64, z:\tfloat64\n",
        "# run_ID:\tint64, rerun_ID:\tint64, cam_col:\tint64, field_ID:\tint64, spec_obj_ID:\tfloat64, class:\tobject,\n",
        "# redshift:\tfloat64, plate:\tint64, MJD:\tint64, fiber_ID:\tint64\n",
        "\n",
        "# 2.1) Display the first 5 and last 5 rows\n",
        "print(\"EXERCISE 2.1\")\n",
        "print(\"First 5 rows:\")\n",
        "print(data.head())\n",
        "print(\"\\nLast 5 rows:\")\n",
        "print(data.tail())\n",
        "\n",
        "# 2.2) Check for missing values in each column\n",
        "print(\"\\nEXERCISE 2.2\")\n",
        "print(\"Missing values in each column:\")\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# 2.3) Check the class distribution i.e. number of samples for each class\n",
        "print(\"\\nEXERCISE 2.3\")\n",
        "print(\"Class distribution:\")\n",
        "print(data['class'].value_counts())\n",
        "\n",
        "# 3.1.) # Display summary statistics for numerical features\n",
        "print(\"\\nEXERCISE 3.1\")\n",
        "print(data.describe()) # by default provides 25%, 50%, 75%\n",
        "print(data.describe(percentiles=[.25, .3, .5, .75]))\n",
        "\n",
        "# 3.2) Plot a bar plot for the class distribution. Ensure your plot has: axis labels, descriptive title,\n",
        "# color and name for each class bar\n",
        "# Calculate the class distribution\n",
        "print(\"\\nEXERCISE 3.2\")\n",
        "class_counts = data['class'].value_counts()\n",
        "plt.figure(figsize=(8,6))\n",
        "bars = class_counts.plot(kind='bar', color=['#3498db', '#e74c3c', '#2ecc71'])\n",
        "plt.xlabel('Class', fontsize=12)\n",
        "plt.ylabel('Number of Samples', fontsize=12)\n",
        "plt.title('Class Distribution in the Dataset', fontsize=14)\n",
        "# Add the names (class labels) for each bar\n",
        "for i, v in enumerate(class_counts):\n",
        "    plt.text(i, v + 5, str(v), ha='center', color='black', fontsize=12)\n",
        "plt.xticks(rotation=0)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# 3.3) Choose two features (e.g., delta and alpha) and create a 2D scatter plot to visualize patterns in the\n",
        "# dataset. Color the points according to their class. Make sure to add: axis labels, descriptive title, legend\n",
        "print(\"\\nEXERCISE 3.3\")\n",
        "feature_x = 'delta'\n",
        "feature_y = 'alpha'\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "for class_value in data['class'].unique():\n",
        "    class_data = data[data['class'] == class_value]\n",
        "    plt.scatter(class_data[feature_x], class_data[feature_y], label=f'Class {class_value}', alpha=0.6)\n",
        "\n",
        "plt.xlabel(feature_x, fontsize=12)\n",
        "plt.ylabel(feature_y, fontsize=12)\n",
        "plt.title(f'{feature_x} vs {feature_y} by Class', fontsize=14)\n",
        "\n",
        "plt.legend(title='Class')\n",
        "plt.show()\n",
        "\n",
        "# 4.1) Discard all columns that represent IDs or metadata (e.g., obj_ID, run_ID, plate, etc.) because those\n",
        "# are not particullary useful for ML models. Retain only the following columns: u, g, r, i, z, redshift, and class.\n",
        "print(\"\\nEXERCISE 4.1\")\n",
        "columns_to_keep = ['u', 'g', 'r', 'i', 'z', 'redshift', 'class']\n",
        "data_cleaned = data[columns_to_keep]\n",
        "print(data_cleaned.head(20))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HLFBS4ybib0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **Assignment 2: MEDMNIST Dataset** (2 points)\n",
        "\n",
        "You are already familiar with the MNIST digits dataset. MEDMNIST is a collection of medical image datasets designed for machine learning tasks in the medical domain. Explore the [MEDMNIST website](https://medmnist.com/) and select a dataset of your choice. Perform the following tasks:\n",
        "\n",
        "---\n",
        "\n",
        "### **Instructions**  \n",
        "1. **Dataset Overview**  \n",
        "   - What is the dataset you chose about?  \n",
        "   - What is the format/type of the data (e.g., images, tabular data, etc.)?  \n",
        "   - What are the inputs and outputs in this dataset?  \n",
        "   - What is the targeted task (e.g., classification, regression, etc.)?  \n",
        "   - Draw a black-box input-output diagram to illustrate the dataset's structure.  \n",
        "\n",
        "2. **Dataset Exploration**  \n",
        "   - How many instances/samples does the dataset have?  \n",
        "   - In which Python data type is the data stored (e.g., NumPy arrays, Pandas DataFrame, etc.)?  \n",
        "   - What are the shapes of the samples?\n",
        "\n",
        "---\n",
        "\n",
        "Make sure to include detailed explanations and any relevant code to justify your answers."
      ],
      "metadata": {
        "id": "dZk_wgfFfarq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is the code you can use to get the data."
      ],
      "metadata": {
        "id": "LcGgcPnkaTgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install medmnist"
      ],
      "metadata": {
        "id": "mHebpCk5Hy9w",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import medmnist\n",
        "from medmnist import INFO, Evaluator\n",
        "from medmnist.dataset import BloodMNIST\n",
        "# from medmnist.dataset import SynapseMNIST3D"
      ],
      "metadata": {
        "id": "gPvXleN2H15_"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_flag = 'bloodmnist' # change this string to get the dataset you want, e.g. 'bloodmnist', 'dermamnist', 'pathmnist' ...\n",
        "data_flag = 'bloodmnist'\n",
        "info = INFO[data_flag]\n",
        "task = info['task']\n",
        "DataClass = getattr(medmnist.dataset, info['python_class'])\n",
        "\n",
        "classes = info['label']\n",
        "\n",
        "# Print classes\n",
        "for label, name in classes.items():\n",
        "    print(f\"Class {label}: {name}\")"
      ],
      "metadata": {
        "id": "zuAJjhxlX1Vd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the data\n",
        "train_dataset = DataClass(split='train', download=True)\n",
        "test_dataset = DataClass(split='test', download=True)\n",
        "val_dataset = DataClass(split='val', download=True)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "k9Wz599qX5tl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"TRAIN DATASET\")\n",
        "print(train_dataset)\n",
        "print(\"===================\")\n",
        "print(\"TEST DATASET\")\n",
        "print(test_dataset)\n",
        "print(\"===================\")\n",
        "print(\"VAL DATASET\")\n",
        "print(val_dataset)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "2I3ZgSLkYFYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can access the images and the labels using train_dataset.imgs and train_dataset.labels. The example is shown below."
      ],
      "metadata": {
        "id": "IV7u7fXvZaW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.imgs                  # see all images 5-dimensional array\n",
        "# train_dataset.imgs[0]             # see individual image\n",
        "# train_dataset.imgs[0][0]          # see 28 rows with 3 rgb propertiesof an image\n",
        "# train_dataset.imgs[0][0][0]       # see individual row with 3 rgb properties\n",
        "# train_dataset.imgs[0][0][0][0]    # see a single property of a row"
      ],
      "metadata": {
        "collapsed": true,
        "id": "MysyV8G7YKAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.labels"
      ],
      "metadata": {
        "collapsed": true,
        "id": "kksgYnZAYL4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualization\n",
        "train_dataset.montage(length=20)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "AXCox0SyYjCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.1) What is the dataset you chose about?\n",
        "According to the [documentation](https://medmnist.com/), the BloodMNIST dataset consists of 17,092 images of blood cell types (8 classes). The outputs of print() method when train_dataset, test_dataset and val_dataset specifies that images are 3×28×28 pixels. The dataset is split into train (11,959), val (1,712) and test (3,421) sets. The task is multi-class classification. There are the following classes within this dataset:\n",
        "- Basophil\n",
        "- Eosinophil\n",
        "- Erythroblast\n",
        "- Immature granulocytes (myelocytes, metamyelocytes, promyelocytes)\n",
        "- Lymphocyte\n",
        "- Monocyte\n",
        "- Neutrophil\n",
        "- Platelet\n",
        "\n",
        "Code to see the dataset classes\n",
        "data_flag = 'bloodmnist'\n",
        "info = INFO[data_flag]\n",
        "classes = info['label']\n",
        "\n",
        "for label, name in classes.items():\n",
        "    print(f\"Class {label}: {name}\")\n",
        "\n",
        "Data description\n",
        "The dataset consists of 5 levels\n",
        "The first level contains individual images as described in the documentation (3x28x28). The next level contains 28 arrays, each of which has a structure of 3 elements and 28 rows and it can be seen via this code val_dataset.imgs[0][0] and each row can be seen via this code val_dataset.imgs[0][0][0]. Finally, the rgb values can be seen via this code val_dataset.imgs[0][0][0][1]. Therefore, if we want to see the color of individual dot we can do it via al_dataset.imgs[0][0][0]. See the following link for more info https://www.rapidtables.com/web/color/RGB_Color.html\n",
        "\n",
        "1.2) What is the format/type of the data (e.g., images, tabular data, etc.)?\n",
        "The data is in the format of images. Each image is represented as a 3D array with dimensions (28, 28, 3), where 28x28 represents the pixel grid, and 3 corresponds to the RGB color channels.\n",
        "\n",
        "1.3) What are the inputs and outputs in this dataset?\n",
        "Inputs: Images, represented as 3D arrays of shape (28, 28, 3) (RGB pixel values), as explained above.\n",
        "Outputs: Class labels, representing the categories (e.g., Basophil, Eosinophil, Erythroblast, etc.), see 1 above for more details.\n",
        "\n",
        "1.4) What is the targeted task (e.g., classification, regression, etc.)?\n",
        "The targeted task is classification, not regression. The goal is to classify each input image into one of the predefined classes, see 1 above.\n",
        "\n",
        "1.5) Draw a black-box input-output diagram to illustrate the dataset's structure (click to open and see the black box).\n",
        "+-------------------+\n",
        "|   Input: Image    |\n",
        "|  (28x28x3 Array)  |\n",
        "+-------------------+\n",
        "          |\n",
        "          v\n",
        "  +---------------+\n",
        "  |    Model      |\n",
        "  | (Classification)|\n",
        "  +---------------+\n",
        "          |\n",
        "          v\n",
        "+-------------------------------+\n",
        "| Output: Class Label           |\n",
        "| (Basophil, Eosinophil,         |\n",
        "| Erythroblast, Immature         |\n",
        "| granulocytes, Lymphocyte,      |\n",
        "| Monocyte, Neutrophil, Platelet)|\n",
        "+-------------------------------+\n",
        "\n",
        "2.1) How many instances/samples does the dataset have?\n",
        "The dataset is split into train (11,959), val (1,712) and test (3,421) sets. The task is multi-class classification.\n",
        "\n",
        "2.2) In which Python data type is the data stored (e.g., NumPy arrays, Pandas DataFrame, etc.)?\n",
        "The data is stored in NumPy arrays.\n",
        "\n",
        "2.3) What are the shapes of the samples?\n",
        "The shape of each sample is (28, 28, 3), see some of the questions and answers above for more details."
      ],
      "metadata": {
        "id": "vMohbU4-G7yJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Assignment 3: Dataset of your choice** (2 points)\n",
        "\n",
        "Choose a dataset of your choice and repeat the tasks similar to the first two assignments depending of the data format you choose.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mQMeE452IM83"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install medmnist\n",
        "\n",
        "import numpy as np\n",
        "import medmnist\n",
        "from medmnist import INFO, Evaluator\n",
        "from medmnist.dataset import DermaMNIST\n",
        "\n",
        "# data_flag = 'bloodmnist' # change this string to get the dataset you want, e.g. 'bloodmnist', 'dermamnist', 'pathmnist' ...\n",
        "data_flag = 'dermamnist'\n",
        "info = INFO[data_flag]\n",
        "task = info['task']\n",
        "DataClass = getattr(medmnist.dataset, info['python_class'])\n",
        "\n",
        "classes = info['label']\n",
        "\n",
        "# Print classes\n",
        "for label, name in classes.items():\n",
        "    print(f\"Class {label}: {name}\")\n",
        "\n",
        "# load the data\n",
        "train_dataset = DataClass(split='train', download=True)\n",
        "test_dataset = DataClass(split='test', download=True)\n",
        "val_dataset = DataClass(split='val', download=True)\n",
        "\n",
        "print(\"TRAIN DATASET\")\n",
        "print(train_dataset)\n",
        "print(\"===================\")\n",
        "print(\"TEST DATASET\")\n",
        "print(test_dataset)\n",
        "print(\"===================\")\n",
        "print(\"VAL DATASET\")\n",
        "print(val_dataset)\n",
        "\n",
        "\n",
        "train_dataset.imgs                  # see all images 5-dimensional array\n",
        "# train_dataset.imgs[0]             # see individual image\n",
        "# train_dataset.imgs[0][0]          # see 28 rows with 3 rgb propertiesof an image\n",
        "# train_dataset.imgs[0][0][0]       # see individual row with 3 rgb properties\n",
        "# train_dataset.imgs[0][0][0][0]    # see a single property of a row\n",
        "\n",
        "# labels\n",
        "train_dataset.labels\n",
        "\n",
        "# visualization\n",
        "train_dataset.montage(length=20)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTLkDGxJZMaY",
        "outputId": "335aea7d-3de0-4ed3-d46f-cbf450e8dda7"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 0: actinic keratoses and intraepithelial carcinoma\n",
            "Class 1: basal cell carcinoma\n",
            "Class 2: benign keratosis-like lesions\n",
            "Class 3: dermatofibroma\n",
            "Class 4: melanoma\n",
            "Class 5: melanocytic nevi\n",
            "Class 6: vascular lesions\n",
            "Using downloaded and verified file: /root/.medmnist/dermamnist.npz\n",
            "Using downloaded and verified file: /root/.medmnist/dermamnist.npz\n",
            "Using downloaded and verified file: /root/.medmnist/dermamnist.npz\n",
            "TRAIN DATASET\n",
            "Dataset DermaMNIST of size 28 (dermamnist)\n",
            "    Number of datapoints: 7007\n",
            "    Root location: /root/.medmnist\n",
            "    Split: train\n",
            "    Task: multi-class\n",
            "    Number of channels: 3\n",
            "    Meaning of labels: {'0': 'actinic keratoses and intraepithelial carcinoma', '1': 'basal cell carcinoma', '2': 'benign keratosis-like lesions', '3': 'dermatofibroma', '4': 'melanoma', '5': 'melanocytic nevi', '6': 'vascular lesions'}\n",
            "    Number of samples: {'train': 7007, 'val': 1003, 'test': 2005}\n",
            "    Description: The DermaMNIST is based on the HAM10000, a large collection of multi-source dermatoscopic images of common pigmented skin lesions. The dataset consists of 10,015 dermatoscopic images categorized as 7 different diseases, formulized as a multi-class classification task. We split the images into training, validation and test set with a ratio of 7:1:2. The source images of 3×600×450 are resized into 3×28×28.\n",
            "    License: CC BY-NC 4.0\n",
            "===================\n",
            "TEST DATASET\n",
            "Dataset DermaMNIST of size 28 (dermamnist)\n",
            "    Number of datapoints: 2005\n",
            "    Root location: /root/.medmnist\n",
            "    Split: test\n",
            "    Task: multi-class\n",
            "    Number of channels: 3\n",
            "    Meaning of labels: {'0': 'actinic keratoses and intraepithelial carcinoma', '1': 'basal cell carcinoma', '2': 'benign keratosis-like lesions', '3': 'dermatofibroma', '4': 'melanoma', '5': 'melanocytic nevi', '6': 'vascular lesions'}\n",
            "    Number of samples: {'train': 7007, 'val': 1003, 'test': 2005}\n",
            "    Description: The DermaMNIST is based on the HAM10000, a large collection of multi-source dermatoscopic images of common pigmented skin lesions. The dataset consists of 10,015 dermatoscopic images categorized as 7 different diseases, formulized as a multi-class classification task. We split the images into training, validation and test set with a ratio of 7:1:2. The source images of 3×600×450 are resized into 3×28×28.\n",
            "    License: CC BY-NC 4.0\n",
            "===================\n",
            "VAL DATASET\n",
            "Dataset DermaMNIST of size 28 (dermamnist)\n",
            "    Number of datapoints: 1003\n",
            "    Root location: /root/.medmnist\n",
            "    Split: val\n",
            "    Task: multi-class\n",
            "    Number of channels: 3\n",
            "    Meaning of labels: {'0': 'actinic keratoses and intraepithelial carcinoma', '1': 'basal cell carcinoma', '2': 'benign keratosis-like lesions', '3': 'dermatofibroma', '4': 'melanoma', '5': 'melanocytic nevi', '6': 'vascular lesions'}\n",
            "    Number of samples: {'train': 7007, 'val': 1003, 'test': 2005}\n",
            "    Description: The DermaMNIST is based on the HAM10000, a large collection of multi-source dermatoscopic images of common pigmented skin lesions. The dataset consists of 10,015 dermatoscopic images categorized as 7 different diseases, formulized as a multi-class classification task. We split the images into training, validation and test set with a ratio of 7:1:2. The source images of 3×600×450 are resized into 3×28×28.\n",
            "    License: CC BY-NC 4.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[158, 111, 117],\n",
              "       [161, 116, 121],\n",
              "       [164, 121, 130],\n",
              "       [167, 127, 135],\n",
              "       [166, 133, 142],\n",
              "       [169, 139, 147],\n",
              "       [172, 146, 155],\n",
              "       [174, 151, 159],\n",
              "       [185, 162, 168],\n",
              "       [189, 164, 168],\n",
              "       [192, 165, 170],\n",
              "       [197, 167, 169],\n",
              "       [201, 167, 168],\n",
              "       [202, 163, 164],\n",
              "       [196, 154, 155],\n",
              "       [186, 146, 147],\n",
              "       [185, 153, 156],\n",
              "       [185, 156, 160],\n",
              "       [190, 161, 165],\n",
              "       [193, 164, 168],\n",
              "       [194, 165, 169],\n",
              "       [193, 164, 168],\n",
              "       [190, 161, 165],\n",
              "       [188, 159, 163],\n",
              "       [190, 161, 165],\n",
              "       [189, 160, 164],\n",
              "       [187, 158, 160],\n",
              "       [186, 157, 159]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.1) What is the dataset you chose about?\n",
        "According to the [documentation](https://medmnist.com/), the DermaMNIST dataset consists of 10,015 dermatoscopic images of common pigmented skin lesions, categorized into 7 classes. The images are resized from their original dimensions of 600x450 pixels to 28x28 pixels and have 3 color channels. The dataset is split into three sets: training (7,007 samples), validation (1,003 samples), and testing (2,005 samples), following a 7:1:2 ratio. The task is multi-class classification, where each image is classified into one of the seven lesion types. There are the following classes within this dataset:\n",
        "- actinic keratoses and intraepithelial carcinoma\n",
        "- basal cell carcinoma\n",
        "- benign keratosis-like lesions\n",
        "- dermatofibroma\n",
        "- melanoma\n",
        "- melanocytic nevi\n",
        "- vascular lesions\n",
        "\n",
        "Code to see the dataset classes\n",
        "data_flag = 'dermamnist'\n",
        "info = INFO[data_flag]\n",
        "classes = info['label']\n",
        "\n",
        "for label, name in classes.items():\n",
        "    print(f\"Class {label}: {name}\")\n",
        "\n",
        "Data description\n",
        "The dataset consists of 5 levels\n",
        "The first level contains individual images as described in the documentation (3x28x28). The next level contains 28 arrays, each of which has a structure of 3 elements and 28 rows and it can be seen via this code val_dataset.imgs[0][0] and each row can be seen via this code val_dataset.imgs[0][0][0]. Finally, the rgb values can be seen via this code val_dataset.imgs[0][0][0][1]. Therefore, if we want to see the color of individual dot we can do it via al_dataset.imgs[0][0][0]. See the following link for more info https://www.rapidtables.com/web/color/RGB_Color.html\n",
        "\n",
        "1.2) What is the format/type of the data (e.g., images, tabular data, etc.)?\n",
        "Just like in the previous exercise, the data is in the format of images. Each image is represented as a 3D array with dimensions (28, 28, 3), where 28x28 represents the pixel grid, and 3 corresponds to the RGB color channels.\n",
        "\n",
        "1.3) What are the inputs and outputs in this dataset?\n",
        "The same as in the previous exercise:\n",
        "Inputs are the images, represented as 3D arrays of shape (28, 28, 3) (RGB pixel values), as explained above.\n",
        "Outputs are the class labels, representing the categories (e.g.dermatofibroma, melanoma, melanocytic nevi, etc.), see 1 above for more details.\n",
        "\n",
        "1.4) What is the targeted task (e.g., classification, regression, etc.)?\n",
        "The targeted task is classification, not regression. The goal is to classify each input image into one of the predefined classes, see 1 above.\n",
        "\n",
        "1.5) Draw a black-box input-output diagram to illustrate the dataset's structure (click to open and see the black box).\n",
        "+-------------------+\n",
        "|   Input: Image    |\n",
        "|  (28x28x3 Array)  |\n",
        "+-------------------+\n",
        "          |\n",
        "          v\n",
        "  +---------------+\n",
        "  |    Model      |\n",
        "  | (Classification)|\n",
        "  +---------------+\n",
        "          |\n",
        "          v\n",
        "+-------------------------------+\n",
        "| Output: Class Label           |\n",
        "| (Actinic Keratoses and        |\n",
        "| Intraepithelial Carcinoma     |\n",
        "| Basal Cell Carcinoma          |\n",
        "| Benign Keratosis-Like Lesions |\n",
        "| Dermatofibroma                |\n",
        "| Melanoma                      |\n",
        "| Melanocytic Nevi              |\n",
        "| Vascular Lesions)             |\n",
        "+-------------------------------+\n",
        "\n",
        "\n",
        "2.1) How many instances/samples does the dataset have?\n",
        "The dataset is split into three sets: training (7,007 samples), validation (1,003 samples), and testing (2,005 samples), following a 7:1:2 ratio.The task is multi-class classification (7).\n",
        "\n",
        "2.2) In which Python data type is the data stored (e.g., NumPy arrays, Pandas DataFrame, etc.)?\n",
        "The data is stored in NumPy arrays.\n",
        "\n",
        "2.3) What are the shapes of the samples?\n",
        "The shape of each sample is (28, 28, 3), see some of the questions and answers above for more details."
      ],
      "metadata": {
        "id": "oT1vbYxQZS7n"
      }
    }
  ]
}