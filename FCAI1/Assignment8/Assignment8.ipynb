{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Batch Normalization and Weight Decay\n",
        "Two common regularization techniques in CNNs when working with computer vision tasks are Batch Normalization and Weight Decay. Regularization techniques in CNNs are used to prevent overfitting, improve generalization ability and speed up the training process.\n",
        "<br>Gradient descent<br>\n",
        "Gradient descent is a way to adjust model's weights and biases to find the lowest point of error, helping the model make better guesses when it sees new data.\n",
        "<br>Normalization vs standardization<br>\n",
        "Normalization scales data to a range between 0 and 1, while standardization transforms data using the formula (x - m)/sigma, where x is a data point, m is the mean, and sigma is the standard deviation, resulting in data with a mean of 0 and a standard deviation of 1.<br>\n",
        "Exploding gradients is a problem in neural networks where the gradients (which guide how the model learns) become too large, causing the model to make huge, erratic changes to the weights and making the learning process fail.<br>\n",
        "Stochastic Gradient Descent (SGD) is a variation of gradient descent where the model updates its weights using only one random data point at a time, instead of the entire dataset, making the learning process faster and more efficient for large datasets.<br>\n",
        "Batch normalization normalizes the output of each activation function, ensuring that the data entering the next layer has a consistent scale. This helps speed up training and makes it more stable\n",
        "\n"
      ],
      "metadata": {
        "id": "jA8CvbrBuXJ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Batch normalization layer (BNL)\n",
        "Batch Norm is a neural network layer that is now commonly used in many architectures. It often gets added as part of a Linear or Convolutional block and helps to stabilize the network during training.<br>\n",
        "Batch normalization is used to normalize the input to a specific layer so that the distribution of the activations remains stable during training. By controlling the distribution of activations and gradients, the learning process is stabilized, which leads to improved convergence, enables usage of higher learning rates, and has regularization technique (even though this is not its primary purpose). Since this layer enables the normalization process between two consecutive hidden layers, it is usually placed after the convolutional layers (before or after the activation function).\n",
        "<br>BNL Parameters<br>\n",
        "The batch normalization layer has 4 parameters, 2 trainable during the backpropagation (β and γ - used to shift and scale transformed distribution to ensure better performance of the model for the specific task), and 2 non-trainable (moving average mean and variance - used for normalization). Even though moving average mean and variance are not learned from training, their values are estimated from input data during the training phase, and are stored and used during inference."
      ],
      "metadata": {
        "id": "Ee0VzE-e_Ap-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.layers import Input\n",
        "\n",
        "# BATCH NORMALIZATION LAYER\n",
        "model = models.Sequential()\n",
        "\n",
        "# Remove activation function from the Conv2D layer\n",
        "model.add(Input(shape=(32, 32, 3)))\n",
        "model.add(layers.Conv2D(32, (3, 3), padding=\"same\"))\n",
        "\n",
        "# Insert batch normalization\n",
        "model.add(layers.BatchNormalization())\n",
        "\n",
        "# Add activation function\n",
        "model.add(layers.Activation(\"relu\"))\n",
        "\n",
        "# Remove activation function from the Conv2D layer\n",
        "model.add(layers.Conv2D(32, (3, 3), padding=\"same\"))\n",
        "\n",
        "# Insert batch normalization\n",
        "model.add(layers.BatchNormalization())\n",
        "\n",
        "# Add activation function\n",
        "model.add(layers.Activation(\"relu\"))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Dropout(0.2))"
      ],
      "metadata": {
        "id": "HvuAvfYk7oRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Weight decay\n",
        "Weight decay is a regularization technique that penalizes large weights during training. It does this by adding a term to the loss function that encourages smaller values for the model’s weights, thus preventing overfitting. There are multiple version of the weight decay implementation based on the vector norm typed that are added as a penalty to the loss function:\n",
        "\n",
        "1. L1 - Uses L1 vector norm (sum of the absolute weights);\n",
        "2. L2 - Uses L2 vector norm (sum of the squared weights);\n",
        "3. L1L2 - Sum of the absolute and squared weights.\n",
        "\n",
        "By introducing weight decay, we ensure smaller values for the weights, which prevents the model from capturing noise instead of true patterns in the data and improves generalization abilities. Weight decay can be applied on the model’s layers by using the Keras regularizers module."
      ],
      "metadata": {
        "id": "_X93r7AD-fUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.regularizers import l2\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.layers import Input\n",
        "\n",
        "# L2 regularization with 0.001 regularization factor\n",
        "model = models.Sequential()\n",
        "model.add(Input(shape=(32, 32, 3)))\n",
        "model.add(layers.Conv2D(32, (3, 3), padding=\"same\", kernel_regularizer=l2(0.001)))\n",
        "\n",
        "# Batch normalization layer\n",
        "model.add(layers.BatchNormalization())\n",
        "\n",
        "# Activation function\n",
        "model.add(layers.Activation(\"relu\"))\n",
        "\n",
        "# L2 regularization with 0.001 regularization factor\n",
        "# model.add(Input(shape=(32, 32, 3))) # already configured to use input shape (None, 32, 32, 3)\n",
        "model.add(layers.Conv2D(32, (3, 3), padding=\"same\", kernel_regularizer=l2(0.001)))\n",
        "\n",
        "# Batch normalization layer\n",
        "model.add(layers.BatchNormalization())\n",
        "\n",
        "# Activation function\n",
        "model.add(layers.Activation(\"relu\"))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Dropout(0.2))"
      ],
      "metadata": {
        "id": "RNgi27jO_MhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transfer learning\n",
        "Transfer learning is a machine learning technique where a model trained on one task (typically with a large dataset) is reused or \"fine-tuned\" to solve a different, but related, task. The key idea is that knowledge gained from solving one problem can be transferred to help solve a different problem more efficiently, particularly when the new task has limited data. In the context of Convolutional Neural Networks (CNNs), transfer learning leverages pre-trained models (typically trained on large, general-purpose datasets like ImageNet) and adapts them for specific tasks. Some popular pre-trained models for computer vision tasks are VGG16 (or VGG19), ResNet, Inception and MobileNet.<br>\n",
        "CNN architecture can be divided into two main parts:\n",
        "1. Feature extraction layers - Typically consisted of convolutional and pooling layers.\n",
        "2. Classification layers - Dense (fully connected) layers.\n",
        "\n",
        "Considering that, pre-trained models can be used in several different ways:\n",
        "1. One-shot classification - Already pre-trained model is loaded and used for custom task prediction without additional training.\n",
        "2. Transfer learning - Feature extraction layers from pre-trained model are loaded and \"freezed\" so their weights cannot be modified during the training process, while newly created dense layers are added on top of them, which will be trained for custom task on a new dataset.\n",
        "3. Fine-tuning - Feature extraction layers from pre-trained model are loaded and trained along with the classification layers using a small learning rate for a new custom task.\n"
      ],
      "metadata": {
        "id": "He15V9F6A97u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Neural network VGG16\n",
        "VGG16 is a 16-layer deep neural network with a straightforward architecture. It exclusively uses 3x3 convolutional filters with a stride of 1, and 2x2 max-pooling layers with a stride of 2, arranged in 5 convolutional blocks (with various number of Conv2D layers, MaxPooling layer and ReLU activation function). It was originally trained on 224x224x3 size images.\n",
        "https://keras.io/api/applications/vgg/#vgg16-function"
      ],
      "metadata": {
        "id": "C9vtFvG4Ckq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications import VGG16\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.layers import Input\n",
        "\n",
        "# Load the VGG16 model which is pre-trained on ImageNet data and exclude top layer\n",
        "# When loading the VGG16 model, the input_shape parameter should be (32, 32, 3) to match the shape of\n",
        "# the CIFAR-10 images, since the original VGG16 model was trained on images with different resolution (224x224x3)\n",
        "vgg_base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(32, 32, 3))\n",
        "\n",
        "# Freeze the VGG16 model layers to prevent training them\n",
        "vgg_base_model.trainable = False\n",
        "\n",
        "# On top of the VGG16 feature extraction model, we can add fully connected layers for classification purpose\n",
        "model = models.Sequential()\n",
        "\n",
        "# Add the base VGG16 model\n",
        "model.add(vgg_base_model)\n",
        "\n",
        "# Add fully connected layers on top of VGG16 base model\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Activation(\"relu\"))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(10, activation=\"softmax\"))\n",
        "\n",
        "# Finally, the code for loading and unfreezing certain VGG16 layers is provided\n",
        "base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(32, 32, 3))\n",
        "base_model.trainable = False\n",
        "set_trainable = False\n",
        "\n",
        "# Unfreeze layers from block5_conv1 onwards\n",
        "for layer in base_model.layers:\n",
        "  if layer.name == \"block5_conv1\":\n",
        "    set_trainable = True\n",
        "  if set_trainable:\n",
        "    layer.trainable = True\n",
        "  else:\n",
        "    layer.trainable = False\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O84wVHboCwzx",
        "outputId": "805328e4-b15d-49dc-d6b1-9b3d0d27c61b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<MaxPooling2D name=block5_pool, built=True>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Assignment 1\n",
        "1. In the final model from the last lab exercise (Figure 4), insert a batch normalization layer between every convolutional layer and activation function. Also, add batch normalization between the first dense layer and\n",
        "activation function."
      ],
      "metadata": {
        "id": "PNN50JPREW6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.optimizers import SGD\n",
        "from tensorflow.keras.layers import Input\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Dropout\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "(trainX, trainy), (testX, testy) = cifar10.load_data() # load data\n",
        "\n",
        "# One-hot encoding for labels\n",
        "trainy = to_categorical(trainy, 10)\n",
        "testy = to_categorical(testy, 10)\n",
        "\n",
        "# Convert images to float32 and scale them\n",
        "trainX = trainX.astype('float32') / 255.0\n",
        "testX = testX.astype('float32') / 255.0\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# First Conv2D Block\n",
        "model.add(Input(shape=(32, 32, 3)))\n",
        "model.add(Conv2D(32, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())  # Batch Normalization\n",
        "model.add(Activation('relu'))    # Activation after Batch Normalization\n",
        "model.add(Conv2D(32, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())  # Batch Normalization\n",
        "model.add(Activation('relu'))    # Activation after Batch Normalization\n",
        "model.add(MaxPooling2D((3, 3)))\n",
        "model.add(Dropout(0.2))  # Dropout after first MaxPooling2D\n",
        "\n",
        "# Second Conv2D Block\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())  # Batch Normalization\n",
        "model.add(Activation('relu'))    # Activation after Batch Normalization\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())  # Batch Normalization\n",
        "model.add(Activation('relu'))    # Activation after Batch Normalization\n",
        "model.add(MaxPooling2D((3, 3)))\n",
        "model.add(Dropout(0.2))  # Dropout after second MaxPooling2D\n",
        "\n",
        "# Third Conv2D Block (newly added)\n",
        "model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())  # Batch Normalization\n",
        "model.add(Activation('relu'))    # Activation after Batch Normalization\n",
        "model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())  # Batch Normalization\n",
        "model.add(Activation('relu'))    # Activation after Batch Normalization\n",
        "model.add(MaxPooling2D((3, 3)))\n",
        "model.add(Dropout(0.2))  # Dropout after third MaxPooling2D\n",
        "\n",
        "# Flatten Layer\n",
        "model.add(Flatten())\n",
        "\n",
        "# Dense Layer with Batch Normalization\n",
        "model.add(Dense(128))\n",
        "model.add(BatchNormalization())  # Batch Normalization\n",
        "model.add(Activation('relu'))    # Activation after Batch Normalization\n",
        "\n",
        "# Dropout after Dense layer\n",
        "model.add(Dropout(0.2))  # Dropout after first Dense layer\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "opt = SGD(learning_rate=0.001, momentum=0.9)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(trainX, trainy, epochs=5, batch_size=64, validation_data=(testX, testy), verbose=1)\n",
        "\n",
        "# Print accuracy vs loss\n",
        "for epoch in range(5):\n",
        "    print(f\"Epoch {epoch + 1}: Accuracy = {history.history['accuracy'][epoch]}, Loss = {history.history['loss'][epoch]}\")\n",
        "\n",
        "# Print final loss and accuracy\n",
        "print(f\"\\nFinal Loss: {history.history['loss'][-1]}, Final Accuracy: {history.history['accuracy'][-1]}\")\n"
      ],
      "metadata": {
        "id": "PVVwYsjdFBwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot the accuracy vs loss\n",
        "Plot the behavior of accuracy and loss over the epochs.\n",
        "1. What can you conclude from the plots?"
      ],
      "metadata": {
        "id": "o9JcsgruRy7k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot accuracy and loss\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.title('Training Accuracy and Loss Over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Value')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "zlbJSG3ZSA55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reduce the batch normalization momentum\n",
        "Instability in validation accuracy is a common issue that can arise due to interactions between batch normalization and other training setup (e.g., optimizer, learning rate). The easiest solution is to reduce the batch normalization’s momentum (default 0.99), while keeping our base architecture the same."
      ],
      "metadata": {
        "id": "sS40zr7LSDzJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.optimizers import SGD\n",
        "from tensorflow.keras.layers import Input\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Dropout\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "(trainX, trainy), (testX, testy) = cifar10.load_data() # load data\n",
        "\n",
        "# One-hot encoding for labels\n",
        "trainy = to_categorical(trainy, 10)\n",
        "testy = to_categorical(testy, 10)\n",
        "\n",
        "# Convert images to float32 and scale them\n",
        "trainX = trainX.astype('float32') / 255.0\n",
        "testX = testX.astype('float32') / 255.0\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# First Conv2D Block\n",
        "model.add(Input(shape=(32, 32, 3)))\n",
        "model.add(Conv2D(32, (3, 3), padding='same'))\n",
        "# model.add(BatchNormalization())  # Batch Normalization\n",
        "model.add(BatchNormalization(momentum=0.8)) # Batch Normalization Reduced\n",
        "model.add(Activation('relu'))    # Activation after Batch Normalization\n",
        "model.add(Conv2D(32, (3, 3), padding='same'))\n",
        "# model.add(BatchNormalization())  # Batch Normalization\n",
        "model.add(BatchNormalization(momentum=0.8)) # Batch Normalization Reduced\n",
        "model.add(Activation('relu'))    # Activation after Batch Normalization\n",
        "model.add(MaxPooling2D((3, 3)))\n",
        "model.add(Dropout(0.2))  # Dropout after first MaxPooling2D\n",
        "\n",
        "# Second Conv2D Block\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "# model.add(BatchNormalization())  # Batch Normalization\n",
        "model.add(BatchNormalization(momentum=0.8)) # Batch Normalization Reduced\n",
        "model.add(Activation('relu'))    # Activation after Batch Normalization\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "# model.add(BatchNormalization())  # Batch Normalization\n",
        "model.add(BatchNormalization(momentum=0.8)) # Batch Normalization Reduced\n",
        "model.add(Activation('relu'))    # Activation after Batch Normalization\n",
        "model.add(MaxPooling2D((3, 3)))\n",
        "model.add(Dropout(0.2))  # Dropout after second MaxPooling2D\n",
        "\n",
        "# Third Conv2D Block (newly added)\n",
        "model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "# model.add(BatchNormalization())  # Batch Normalization\n",
        "model.add(BatchNormalization(momentum=0.8)) # Batch Normalization Reduced\n",
        "model.add(Activation('relu'))    # Activation after Batch Normalization\n",
        "model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "# model.add(BatchNormalization())  # Batch Normalization\n",
        "model.add(BatchNormalization(momentum=0.8)) # Batch Normalization Reduced\n",
        "model.add(Activation('relu'))    # Activation after Batch Normalization\n",
        "model.add(MaxPooling2D((3, 3)))\n",
        "model.add(Dropout(0.2))  # Dropout after third MaxPooling2D\n",
        "\n",
        "# Flatten Layer\n",
        "model.add(Flatten())\n",
        "\n",
        "# Dense Layer with Batch Normalization\n",
        "model.add(Dense(128))\n",
        "#model.add(BatchNormalization())  # Batch Normalization\n",
        "model.add(BatchNormalization(momentum=0.8)) # Batch Normalization Reduced\n",
        "model.add(Activation('relu'))    # Activation after Batch Normalization\n",
        "\n",
        "# Dropout after Dense layer\n",
        "model.add(Dropout(0.2))  # Dropout after first Dense layer\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "opt = SGD(learning_rate=0.001, momentum=0.9)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(trainX, trainy, epochs=5, batch_size=64, validation_data=(testX, testy), verbose=1)\n",
        "\n",
        "# Print accuracy vs loss\n",
        "for epoch in range(5):\n",
        "    print(f\"Epoch {epoch + 1}: Accuracy = {history.history['accuracy'][epoch]}, Loss = {history.history['loss'][epoch]}\")\n",
        "\n",
        "# Print final loss and accuracy\n",
        "print(f\"\\nFinal Loss: {history.history['loss'][-1]}, Final Accuracy: {history.history['accuracy'][-1]}\")\n",
        "\n",
        "# Plot accuracy and loss\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.title('Training Accuracy and Loss Over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Value')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7eBQvtWnS12o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding weight decay\n",
        "In addition to the previously added batch normalization (with momentum 0.8), add weight decay. More precisely, add the L2 regularizer with regularization factor of 0.001 to every Conv2D and first Dense layer."
      ],
      "metadata": {
        "id": "imCGaWtHUIQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.optimizers import SGD\n",
        "from tensorflow.keras.layers import Input\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Dropout\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "(trainX, trainy), (testX, testy) = cifar10.load_data() # load data\n",
        "\n",
        "# One-hot encoding for labels\n",
        "trainy = to_categorical(trainy, 10)\n",
        "testy = to_categorical(testy, 10)\n",
        "\n",
        "# Convert images to float32 and scale them\n",
        "trainX = trainX.astype('float32') / 255.0\n",
        "testX = testX.astype('float32') / 255.0\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# First Conv2D Block\n",
        "model.add(Input(shape=(32, 32, 3)))\n",
        "model.add(Conv2D(32, (3, 3), padding='same', kernel_regularizer=l2(0.001)))\n",
        "model.add(BatchNormalization(momentum=0.8)) # Batch Normalization Reduced\n",
        "model.add(Activation('relu'))    # Activation after Batch Normalization\n",
        "model.add(Conv2D(32, (3, 3), padding='same', kernel_regularizer=l2(0.001)))\n",
        "# model.add(BatchNormalization())  # Batch Normalization\n",
        "model.add(BatchNormalization(momentum=0.8)) # Batch Normalization Reduced\n",
        "model.add(Activation('relu'))    # Activation after Batch Normalization\n",
        "model.add(MaxPooling2D((3, 3)))\n",
        "model.add(Dropout(0.2))  # Dropout after first MaxPooling2D\n",
        "\n",
        "# Second Conv2D Block\n",
        "model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=l2(0.001)))\n",
        "model.add(BatchNormalization(momentum=0.8)) # Batch Normalization Reduced\n",
        "model.add(Activation('relu'))    # Activation after Batch Normalization\n",
        "model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=l2(0.001)))\n",
        "model.add(BatchNormalization(momentum=0.8)) # Batch Normalization Reduced\n",
        "model.add(Activation('relu'))    # Activation after Batch Normalization\n",
        "model.add(MaxPooling2D((3, 3)))\n",
        "model.add(Dropout(0.2))  # Dropout after second MaxPooling2D\n",
        "\n",
        "# Third Conv2D Block (newly added)\n",
        "model.add(Conv2D(128, (3, 3), padding='same', kernel_regularizer=l2(0.001)))\n",
        "# model.add(BatchNormalization())  # Batch Normalization\n",
        "model.add(BatchNormalization(momentum=0.8)) # Batch Normalization Reduced\n",
        "model.add(Activation('relu'))    # Activation after Batch Normalization\n",
        "model.add(Conv2D(128, (3, 3), padding='same', kernel_regularizer=l2(0.001)))\n",
        "# model.add(BatchNormalization())  # Batch Normalization\n",
        "model.add(BatchNormalization(momentum=0.8)) # Batch Normalization Reduced\n",
        "model.add(Activation('relu'))    # Activation after Batch Normalization\n",
        "model.add(MaxPooling2D((3, 3)))\n",
        "model.add(Dropout(0.2))  # Dropout after third MaxPooling2D\n",
        "\n",
        "# Flatten Layer\n",
        "model.add(Flatten())\n",
        "\n",
        "# Dense Layer with Batch Normalization\n",
        "model.add(Dense(128, kernel_regularizer=l2(0.001)))\n",
        "model.add(BatchNormalization(momentum=0.8)) # Batch Normalization Reduced\n",
        "model.add(Activation('relu'))    # Activation after Batch Normalization\n",
        "\n",
        "# Dropout after Dense layer\n",
        "model.add(Dropout(0.2))  # Dropout after first Dense layer\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "opt = SGD(learning_rate=0.001, momentum=0.9)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(trainX, trainy, epochs=5, batch_size=64, validation_data=(testX, testy), verbose=1)\n",
        "\n",
        "# Print accuracy vs loss\n",
        "for epoch in range(5):\n",
        "    print(f\"Epoch {epoch + 1}: Accuracy = {history.history['accuracy'][epoch]}, Loss = {history.history['loss'][epoch]}\")\n",
        "\n",
        "# Print final loss and accuracy\n",
        "print(f\"\\nFinal Loss: {history.history['loss'][-1]}, Final Accuracy: {history.history['accuracy'][-1]}\")\n",
        "\n",
        "# Plot accuracy and loss\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.title('Training Accuracy and Loss Over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Value')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "OQfTsKGXUSis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model comparison\n",
        "Compare the accuracy obtained by using these three models. The expected accuracy per model type is:\n",
        "\n",
        "Baseline model 73 - 76%\n",
        "Baseline model + BN 80 - 82%\n",
        "Baseline model + BN + L2 83 - 85%\n",
        "\n",
        "1. Explain the increase in accuracy after every modification."
      ],
      "metadata": {
        "id": "kNikGuBmWeZw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing batch normalization, momentum and l2\n",
        "Try different values for the batch normalization momentum and l2 parameters. Record the behavior of these models. Did you achieve better performance, and using which values of these parameters?"
      ],
      "metadata": {
        "id": "awC2googW7SW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Assignment 2\n",
        "1) Using the provided code samples in the VGG16 section, load the VGG16 model by excluding the top layer. Freeze all VGG16 model layers to prevent training them. Build the transfer learning model by adding the base VGG16 model and the same fully connected layers as shown in the code snippet above."
      ],
      "metadata": {
        "id": "71tdSmyKXWam"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications import VGG16\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.layers import Input\n",
        "\n",
        "# Load the VGG16 model pre-trained on ImageNet data, excluding the top layer.\n",
        "# Set input shape to (32, 32, 3) for CIFAR-10 compatibility.\n",
        "vgg_base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(32, 32, 3))\n",
        "\n",
        "# Freeze all layers of the VGG16 model to prevent them from being trained initially.\n",
        "vgg_base_model.trainable = False\n",
        "\n",
        "# Build the transfer learning model.\n",
        "model = models.Sequential()\n",
        "\n",
        "# Add the base VGG16 model.\n",
        "model.add(vgg_base_model)\n",
        "\n",
        "# Add fully connected layers on top for classification.\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Activation(\"relu\"))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(10, activation=\"softmax\"))  # 10 classes for CIFAR-10.\n",
        "\n",
        "# Print the model summary to verify the architecture.\n",
        "model.summary()\n",
        "\n",
        "# OPTIONAL: Unfreeze specific layers from block5_conv1 onward for fine-tuning.\n",
        "set_trainable = False\n",
        "for layer in vgg_base_model.layers:\n",
        "    if layer.name == \"block5_conv1\":\n",
        "        set_trainable = True\n",
        "    layer.trainable = set_trainable\n",
        "\n",
        "# Print a summary to verify the trainable status of each layer.\n",
        "for layer in vgg_base_model.layers:\n",
        "    print(f\"Layer: {layer.name}, Trainable: {layer.trainable}\")\n"
      ],
      "metadata": {
        "id": "tOKhQOJtIGOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Compile this model by using a smaller learning rate (e.g., lr= 0.0001). Perform training and evaluation of the\n",
        "model on the CIFAR-10 dataset. What accuracy is achieved? Is this result satisfactory?"
      ],
      "metadata": {
        "id": "j0InNsOJKIu1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to the range [0, 1]\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "# Convert class labels to one-hot encoding\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train, epochs=10, batch_size=64, validation_split=0.2, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss_i, test_accuracy_i = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(f\"Iteration I Test Accuracy: {test_accuracy_i:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sL7F26DnKuee",
        "outputId": "e69627b0-bc1d-4dda-d667-de4a9c2713af"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 17ms/step - accuracy: 0.5162 - loss: 1.4481 - val_accuracy: 0.7161 - val_loss: 0.8138\n",
            "Epoch 2/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 14ms/step - accuracy: 0.7517 - loss: 0.7339 - val_accuracy: 0.7982 - val_loss: 0.5834\n",
            "Epoch 3/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.8025 - loss: 0.5742 - val_accuracy: 0.8112 - val_loss: 0.5515\n",
            "Epoch 4/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.8462 - loss: 0.4492 - val_accuracy: 0.8131 - val_loss: 0.5566\n",
            "Epoch 5/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.8803 - loss: 0.3578 - val_accuracy: 0.8215 - val_loss: 0.5296\n",
            "Epoch 6/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.9072 - loss: 0.2821 - val_accuracy: 0.8202 - val_loss: 0.5341\n",
            "Epoch 7/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.9340 - loss: 0.2128 - val_accuracy: 0.8393 - val_loss: 0.4870\n",
            "Epoch 8/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.9531 - loss: 0.1607 - val_accuracy: 0.8476 - val_loss: 0.4784\n",
            "Epoch 9/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.9693 - loss: 0.1130 - val_accuracy: 0.8503 - val_loss: 0.4794\n",
            "Epoch 10/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.9775 - loss: 0.0866 - val_accuracy: 0.8511 - val_loss: 0.5037\n",
            "313/313 - 2s - 6ms/step - accuracy: 0.8415 - loss: 0.5184\n",
            "Iteration I Test Accuracy: 0.84\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Perform the model fine-tuning by unfreezing the last three layers of the base VGG16 model. Evaluate this model and explain the differences in results obtained using transfer learning with and without fine-tuning.<br>\n",
        "Answer<br>\n",
        "The fine-tuned model achieved a slightly higher test accuracy (0.75 vs. 0.73), indicating improved performance after fine-tuning. However, the test loss increased (1.74 vs. 1.21), suggesting that fine-tuning may have led to overfitting or less generalization on the test data."
      ],
      "metadata": {
        "id": "-6CIxM5rUM5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfreeze the last 3 layers of the VGG16 model\n",
        "vgg_base_model.trainable = True\n",
        "for layer in vgg_base_model.layers[:-3]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Re-compile the model after unfreezing layers\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the fine-tuned model again if needed\n",
        "history_fine_tune = model.fit(x_train, y_train, epochs=10, batch_size=64, validation_split=0.2, verbose=1)\n",
        "\n",
        "# Evaluate the fine-tuned model\n",
        "test_loss_fine_tune, test_accuracy_fine_tune = model.evaluate(x_test, y_test, verbose=2)\n",
        "\n",
        "# Evaluate the fine-tuned model (Iteration II)\n",
        "test_loss_ii, test_accuracy_ii = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(f\"Iteration II Test Accuracy: {test_accuracy_ii:.2f}, Test Loss: {test_loss_ii:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ixr5Z9SUPrk",
        "outputId": "8e76dd72-0f3c-4a0b-f367-d156acd9ada9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9860 - loss: 0.0592 - val_accuracy: 0.8628 - val_loss: 0.4617\n",
            "Epoch 2/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.9923 - loss: 0.0390 - val_accuracy: 0.8642 - val_loss: 0.4745\n",
            "Epoch 3/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9951 - loss: 0.0289 - val_accuracy: 0.8623 - val_loss: 0.4991\n",
            "Epoch 4/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9958 - loss: 0.0252 - val_accuracy: 0.8626 - val_loss: 0.5054\n",
            "Epoch 5/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9966 - loss: 0.0201 - val_accuracy: 0.8643 - val_loss: 0.5239\n",
            "Epoch 6/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9968 - loss: 0.0185 - val_accuracy: 0.8630 - val_loss: 0.5348\n",
            "Epoch 7/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.9976 - loss: 0.0147 - val_accuracy: 0.8658 - val_loss: 0.5461\n",
            "Epoch 8/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9978 - loss: 0.0140 - val_accuracy: 0.8619 - val_loss: 0.5654\n",
            "Epoch 9/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9980 - loss: 0.0125 - val_accuracy: 0.8627 - val_loss: 0.5791\n",
            "Epoch 10/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.9983 - loss: 0.0117 - val_accuracy: 0.8631 - val_loss: 0.5905\n",
            "313/313 - 2s - 5ms/step - accuracy: 0.8606 - loss: 0.5945\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.8606 - loss: 0.5945\n",
            "Iteration II Test Accuracy: 0.86, Test Loss: 0.59\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) Load the VGG16 model again, but this time only up to the third convolutional block. Unfreeze layers from the third convolutional block. Build the new transfer learning model by adding the block3 model and the same fully connected layers as\n",
        "shown in the code snippet above."
      ],
      "metadata": {
        "id": "PL8PEhxZZK3T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import models\n",
        "\n",
        "# Load the VGG16 model and take only up to block3\n",
        "vgg_base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(32, 32, 3))\n",
        "block3_output = vgg_base_model.get_layer(\"block3_pool\").output\n",
        "block3_model = Model(inputs=vgg_base_model.input, outputs=block3_output)\n",
        "\n",
        "# Freeze all layers up to block3, unfreeze block3 for fine-tuning\n",
        "for layer in block3_model.layers:\n",
        "    if \"block3\" in layer.name:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False\n",
        "\n",
        "# Build the model\n",
        "model = models.Sequential()\n",
        "model.add(block3_model)\n",
        "\n",
        "# Add fully connected layers on top of the block3 model\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Activation(\"relu\"))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(10, activation=\"softmax\"))  # 10 classes for CIFAR-10\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model after unfreezing block 2 and block 3\n",
        "history_iii = model.fit(x_train, y_train, epochs=10, batch_size=64, validation_split=0.2, verbose=1)\n",
        "\n",
        "# Evaluate the model after fine-tuning block 2 and block 3 (Iteration III)\n",
        "test_loss_iii, test_accuracy_iii = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(f\"Iteration III Test Accuracy: {test_accuracy_iii:.2f}, Test Loss: {test_loss_iii:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwcLw2D6arvw",
        "outputId": "a971a284-89e8-43af-97fb-2710b7985b52"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.5634 - loss: 1.2923 - val_accuracy: 0.5587 - val_loss: 1.3348\n",
            "Epoch 2/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.7302 - loss: 0.7818 - val_accuracy: 0.7164 - val_loss: 0.7995\n",
            "Epoch 3/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.7745 - loss: 0.6485 - val_accuracy: 0.7547 - val_loss: 0.7366\n",
            "Epoch 4/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.8153 - loss: 0.5423 - val_accuracy: 0.7680 - val_loss: 0.7027\n",
            "Epoch 5/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.8453 - loss: 0.4509 - val_accuracy: 0.8022 - val_loss: 0.6029\n",
            "Epoch 6/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.8719 - loss: 0.3709 - val_accuracy: 0.8069 - val_loss: 0.6171\n",
            "Epoch 7/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - accuracy: 0.8974 - loss: 0.2969 - val_accuracy: 0.7944 - val_loss: 0.6597\n",
            "Epoch 8/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9216 - loss: 0.2323 - val_accuracy: 0.8201 - val_loss: 0.5920\n",
            "Epoch 9/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.9409 - loss: 0.1782 - val_accuracy: 0.7834 - val_loss: 0.8227\n",
            "Epoch 10/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.9509 - loss: 0.1470 - val_accuracy: 0.8127 - val_loss: 0.7400\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.8135 - loss: 0.7303\n",
            "Iteration III Test Accuracy: 0.81, Test Loss: 0.73\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5) Modify the previous model by unfreezing the layers of the second block along with the layers of the third block."
      ],
      "metadata": {
        "id": "MDwk9Ht0chuX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze all layers up to block2, unfreeze block2 and block3 for fine-tuning\n",
        "for layer in block3_model.layers:\n",
        "  if \"block2\" in layer.name or \"block3\" in layer.name:\n",
        "    layer.trainable = True\n",
        "  else:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Re-compile the model after unfreezing layers\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the fine-tuned model again (Iteration IV)\n",
        "history_iv = model.fit(x_train, y_train, epochs=10, batch_size=64, validation_split=0.2, verbose=1)\n",
        "\n",
        "# Evaluate the fine-tuned model (Iteration IV)\n",
        "test_loss_iv, test_accuracy_iv = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(f\"Iteration IV Test Accuracy: {test_accuracy_iv:.2f}, Test Loss: {test_loss_iv:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebR4Sl71cwQT",
        "outputId": "cda93b99-5580-4ff5-f21d-8aebefec0fd4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 16ms/step - accuracy: 0.8924 - loss: 0.3213 - val_accuracy: 0.7693 - val_loss: 0.7935\n",
            "Epoch 2/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.9403 - loss: 0.1755 - val_accuracy: 0.8046 - val_loss: 0.7072\n",
            "Epoch 3/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - accuracy: 0.9519 - loss: 0.1429 - val_accuracy: 0.7816 - val_loss: 0.9111\n",
            "Epoch 4/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.9542 - loss: 0.1355 - val_accuracy: 0.7778 - val_loss: 0.9401\n",
            "Epoch 5/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - accuracy: 0.9629 - loss: 0.1067 - val_accuracy: 0.7870 - val_loss: 0.9753\n",
            "Epoch 6/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.9620 - loss: 0.1148 - val_accuracy: 0.8114 - val_loss: 0.8353\n",
            "Epoch 7/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - accuracy: 0.9690 - loss: 0.0899 - val_accuracy: 0.8010 - val_loss: 0.8751\n",
            "Epoch 8/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.9708 - loss: 0.0846 - val_accuracy: 0.8129 - val_loss: 0.8744\n",
            "Epoch 9/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - accuracy: 0.9727 - loss: 0.0805 - val_accuracy: 0.7906 - val_loss: 0.9579\n",
            "Epoch 10/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.9719 - loss: 0.0783 - val_accuracy: 0.7993 - val_loss: 0.8921\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.7871 - loss: 0.9520\n",
            "Iteration IV Test Accuracy: 0.79, Test Loss: 0.95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6) Finally"
      ],
      "metadata": {
        "id": "pe06KjaQdJZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming you have the accuracy values from each model iteration\n",
        "results = [\n",
        "    {\"iteration\": \"I\", \"loaded_vgg16_blocks\": \"All\", \"fine_tuning_performed\": \"No\", \"unfreezed_layers\": \"-\", \"accuracy\": test_accuracy_i},\n",
        "    {\"iteration\": \"II\", \"loaded_vgg16_blocks\": \"All\", \"fine_tuning_performed\": \"Yes\", \"unfreezed_layers\": \"Last 3\", \"accuracy\": test_accuracy_ii},\n",
        "    {\"iteration\": \"III\", \"loaded_vgg16_blocks\": \"First 3\", \"fine_tuning_performed\": \"Yes\", \"unfreezed_layers\": \"Block 3 layers\", \"accuracy\": test_accuracy_iii},\n",
        "    {\"iteration\": \"IV\", \"loaded_vgg16_blocks\": \"First 3\", \"fine_tuning_performed\": \"Yes\", \"unfreezed_layers\": \"Block 2 and block 3 layers\", \"accuracy\": test_accuracy_iv}\n",
        "]\n",
        "\n",
        "# Convert the results to a DataFrame\n",
        "df = pd.DataFrame(results)\n",
        "\n",
        "# Print the table\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbcNW3n2dMNX",
        "outputId": "02589b84-872a-4585-fedf-6a9fb37da4cd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iteration loaded_vgg16_blocks fine_tuning_performed  \\\n",
            "0         I                 All                    No   \n",
            "1        II                 All                   Yes   \n",
            "2       III             First 3                   Yes   \n",
            "3        IV             First 3                   Yes   \n",
            "\n",
            "             unfreezed_layers  accuracy  \n",
            "0                           -    0.8415  \n",
            "1                      Last 3    0.8606  \n",
            "2              Block 3 layers    0.8135  \n",
            "3  Block 2 and block 3 layers    0.7871  \n"
          ]
        }
      ]
    }
  ]
}